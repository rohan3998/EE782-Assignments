{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EE782_assmt2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBmFkBBRq9xw"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold \n",
        "\n",
        "import time\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDJQ2YQnrenj"
      },
      "source": [
        "SEED = 1234\n",
        "\n",
        "# We have looked at https://github.com/bentrevett/pytorch-sentiment-analysis for setting the various values of TEXT and LABEL as we have not worked with this before till now.\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "TEXT = data.Field(tokenize = 'spacy', include_lengths = True)\n",
        "LABEL = data.LabelField(dtype = torch.float)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-X8KmFVirf6D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7720c059-857e-4ee8-d18e-0c1cec616a97"
      },
      "source": [
        "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)                                   #split the data into training and test data\n",
        "train_data, val_data= train_data.split(split_ratio=0.8, random_state=random.seed(SEED))     #split training data into training and validation data\n",
        "\n",
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of validation examples: {len(val_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 20000\n",
            "Number of validation examples: 5000\n",
            "Number of testing examples: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIiN3aVQsIcC"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "382b8Vvv82CJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a25d6c2b-9ce8-4e75-d666-1066694bd7fa"
      },
      "source": [
        "print(vars(train_data.examples[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'text': ['...', 'but', 'a', 'lousy', 'film', '.', 'As', 'Maltin', 'says', 'this', 'was', 'Christopher', 'Lee', \"'s\", 'attempt', 'to', 'make', 'a', 'serious', 'horror', 'film', '.', 'Well', ',', 'it', 'is', 'serious', '...', 'TOO', 'serious', '!', 'The', 'plot', 'is', 'silly', 'and', 'slow', '(', 'something', 'about', 'old', 'people', 'inhabiting', 'the', 'bodies', 'of', 'young', 'children', 'to', 'achieve', 'immortality)', '...', 'the', 'film', 'is', 'all', 'talk', 'talk', 'talk', 'talk', 'talk', 'talk', 'talk', 'about', 'the', 'same', 'things', 'over', 'and', 'over', 'again', '.', 'I', 'actually', 'dozed', 'off', 'a', 'few', 'times', '!', 'The', 'film', 'is', 'sooooo', 'dull', '!', 'The', 'cast', 'sleepwalks', 'through', 'this', 'with', 'the', 'sole', 'exceptions', 'of', 'Peter', 'Cushing', 'and', 'Lee', '...', 'but', 'this', 'was', 'probably', 'a', 'labor', 'of', 'love', 'for', 'both', '(', 'they', 'often', 'complained', 'about', 'horror', 'movies', 'being', 'too', 'violent', '...', 'well', ',', 'this', 'has', 'NO', 'violence', '!', ')', '.', 'Avoid', 'at', 'all', 'costs', '...', 'unless', 'you', 'have', 'insomnia', '...', 'this', 'will', 'put', 'you', 'to', 'sleep', '!'], 'label': 'neg'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2S3m8awz9iLV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff89aa7a-3628-43b3-ac0c-8a73d1fc0ba2"
      },
      "source": [
        "MAX_VOCAB_SIZE = 50000 #consider only the top 50000 used words to build vocabulary/embeddings\n",
        "\n",
        "TEXT.build_vocab(train_data, max_size = MAX_VOCAB_SIZE, vectors = \"glove.6B.100d\", \n",
        "                 unk_init = torch.Tensor.normal_)\n",
        "LABEL.build_vocab(train_data)\n",
        "\n",
        "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
        "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens in TEXT vocabulary: 50002\n",
            "Unique tokens in LABEL vocabulary: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOwuAZqI_XEy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b5a645f-9c8f-415c-9439-75095a539f57"
      },
      "source": [
        "print(TEXT.vocab.freqs.most_common(20))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('the', 231843), (',', 219895), ('.', 189748), ('and', 125166), ('a', 124925), ('of', 115411), ('to', 107330), ('is', 87251), ('in', 70025), ('I', 62108), ('it', 60994), ('that', 56178), ('\"', 50106), (\"'s\", 49515), ('this', 48357), ('-', 42046), ('/><br', 40789), ('was', 39878), ('as', 34817), ('with', 34347)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7X4a_K6_Zfi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0436009b-7c0e-4985-b9ea-7e2ed9065880"
      },
      "source": [
        "print(TEXT.vocab.itos[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<unk>', '<pad>', 'the', ',', '.', 'and', 'a', 'of', 'to', 'is']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phFOPzBx_d1Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6be0850-4824-4c82-b0e5-4ad292fbb506"
      },
      "source": [
        "print(LABEL.vocab.stoi)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "defaultdict(<function _default_unk_index at 0x7f4237351510>, {'neg': 0, 'pos': 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydAQRynr_isw"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "train_iterator, val_iterator, test_iterator = data.BucketIterator.splits(         #make the iterators for train,test,val\n",
        "    (train_data, val_data, test_data), \n",
        "    batch_size = BATCH_SIZE,\n",
        "    sort_within_batch = True,\n",
        "    device = device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MF--D-e8_pVw"
      },
      "source": [
        "#This model has been built from scratch without using the links provided in the doc. The basic framework is taken from https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html\n",
        "\n",
        "class BiLSTM(nn.Module):\n",
        "    def __init__(self,input_dim,embedding_dim,hidden_dim,output_dim,n_layers,bidirectional,dropout,pad_idx):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding=nn.Embedding(input_dim,embedding_dim,padding_idx=pad_idx)\n",
        "\n",
        "        self.lstm=nn.LSTM(embedding_dim, hidden_dim,num_layers=n_layers,bidirectional=bidirectional,dropout=dropout if n_layers>1 else 0)\n",
        "\n",
        "        #self.gru=nn.GRU(embedding_dim, hidden_dim,num_layers=n_layers,bidirectional=bidirectional,dropout=dropout if n_layers>1 else 0)\n",
        "\n",
        "        self.fc=nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "        self.dropout=nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self,text,text_lengths):\n",
        "        embed=self.embedding(text)\n",
        "        #text_lengths = torch.as_tensor(text_lengths, dtype=torch.int64, device='cpu')\n",
        "        #packed_embedded = nn.utils.rnn.pack_padded_sequence(embed, text_lengths) uncomment to introduce padding of sequence\n",
        "        #packed_output, (hidden, cell) = self.lstm(packed_embedded)               uncomment to train lstm with padding\n",
        "        #packed_output, (hidden, cell) = self.gru(packed_embedded)                uncomment to train gru with padding\n",
        "        output, (hidden,cell) = self.lstm(embed)  \n",
        "        #output, hidden = self.gru(embed)                                         uncomment for normal gru\n",
        "        #output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output) uncomment if using padding\n",
        "        #print(hidden.shape)\n",
        "        hidden=self.dropout(hidden)\n",
        "        #hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)) uncomment if using bidirectional lstm only (not gru)\n",
        "        return self.fc(hidden)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8lwyibNR3HY"
      },
      "source": [
        "#pretrained_embeddings = TEXT.vocab.vectors\n",
        "#print(pretrained_embeddings.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKG_ZhiBBTCm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "accf6dc7-4ed0-4a6e-847b-3430baeb9d4a"
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM=1\n",
        "#OUTPUT_DIM = len(LABEL.vocab)\n",
        "N_LAYERS = 1\n",
        "BIDIRECTIONAL = False #keep true if using bidirectional GRU/LSTM\n",
        "DROPOUT = 0.5\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "print(INPUT_DIM)\n",
        "print(OUTPUT_DIM)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "50002\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f02HdLKXCO8J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1b80596-75ee-4db7-f8e5-3745b5cbc70c"
      },
      "source": [
        "model=BiLSTM(INPUT_DIM,EMBEDDING_DIM,HIDDEN_DIM,OUTPUT_DIM,N_LAYERS,BIDIRECTIONAL,DROPOUT,PAD_IDX)  #instantiate the model\n",
        "model.to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)                                                #used Adam optimizer\n",
        "#loss_function = nn.NLLLoss()\n",
        "loss_function=nn.BCEWithLogitsLoss()                                                                #used a variation of binary cross entropy loss\n",
        "loss_function.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BCEWithLogitsLoss()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5IM1dPTR7hm"
      },
      "source": [
        "#model.embedding.weight.data.copy_(pretrained_embeddings)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpF7UCKPwlPv"
      },
      "source": [
        "# We have used this function directly from https://github.com/bentrevett/pytorch-sentiment-analysis but there is nothing new about this as this is a standard implementation\n",
        "def binary_accuracy(preds, y):      #returns the probability of correctly classified data\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float() #convert into float for division \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wVoRY58DpCv"
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OGHVW1Qy8qq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a93884f2-6f2d-4188-cdaf-93bfa01e4b47"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Nov 12 10:12:03 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.32.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    32W / 250W |    883MiB / 16280MiB |      6%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiJ89QiXCz2L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40456059-05bb-4349-9a87-4bc7b5c8af74"
      },
      "source": [
        "num_epochs=20\n",
        "\n",
        "trainloss=[]\n",
        "trainacc=[]\n",
        "valacc=[]\n",
        "valloss=[]\n",
        "\n",
        "#We have used the training and testing loops based on the pytorch link mentioned before. Few changes are there for dimension matching etc.\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  start_time=time.time()\n",
        "  model.train()\n",
        "################################################ TRAINING ################################################\n",
        "  train_acc=0\n",
        "  train_loss=0\n",
        "  for batch in train_iterator:\n",
        "    model.zero_grad()\n",
        "    #print(batch.text.shape)\n",
        "    text, text_lengths= batch.text\n",
        "    #print(sentiment.shape)\n",
        "    sentiment=model(text, text_lengths).squeeze(1)\n",
        "    sentiment=torch.reshape(sentiment,(len(batch.label),))\n",
        "    #print(sentiment.shape)\n",
        "    #print(batch.label.shape)\n",
        "    loss=loss_function(sentiment,batch.label)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_loss=train_loss+loss.item()\n",
        "    #_,indices=torch.max(sentiment,1)\n",
        "    #train_acc=train_acc+torch.mean(torch.tensor(batch.label == indices, dtype=torch.float))\n",
        "    train_acc=train_acc+binary_accuracy(sentiment, batch.label)\n",
        "\n",
        "  train_loss=train_loss/len(train_iterator)\n",
        "  train_acc=train_acc/len(train_iterator)\n",
        "  trainloss.append(float(train_loss))\n",
        "  trainacc.append(float(train_acc))\n",
        "\n",
        "  val_acc=0\n",
        "  val_loss=0\n",
        "  model.eval()\n",
        "\n",
        "############################################################# VALIDATION/TEST ###############################################\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for batch in val_iterator:\n",
        "      text, text_lengths= batch.text\n",
        "      text_lengths = torch.as_tensor(text_lengths, dtype=torch.int64, device='cpu')\n",
        "      prediction=model(text, text_lengths).squeeze(1)\n",
        "      prediction=torch.reshape(prediction,(len(batch.label),))\n",
        "      val_loss=val_loss+loss_function(prediction,batch.label).item()\n",
        "      #_,indices=torch.max(prediction,1)\n",
        "      #val_acc=val_acc+torch.mean(torch.tensor(batch.label == indices, dtype=torch.float))\n",
        "      val_acc=val_acc+binary_accuracy(prediction, batch.label)\n",
        "\n",
        "  val_loss=val_loss/len(val_iterator)\n",
        "  val_acc=val_acc/len(val_iterator)\n",
        "  valloss.append(float(val_loss))\n",
        "  valacc.append(float(val_acc))\n",
        "\n",
        "  end_time=time.time()\n",
        "\n",
        "  epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "  print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "  print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "  print(f'\\t Val. Loss: {val_loss:.3f} |  Val. Acc: {val_acc*100:.2f}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 10s\n",
            "\tTrain Loss: 0.676 | Train Acc: 57.55%\n",
            "\t Val. Loss: 0.745 |  Val. Acc: 57.95%\n",
            "Epoch: 02 | Epoch Time: 0m 10s\n",
            "\tTrain Loss: 0.652 | Train Acc: 61.26%\n",
            "\t Val. Loss: 0.687 |  Val. Acc: 55.24%\n",
            "Epoch: 03 | Epoch Time: 0m 10s\n",
            "\tTrain Loss: 0.606 | Train Acc: 67.65%\n",
            "\t Val. Loss: 0.648 |  Val. Acc: 61.17%\n",
            "Epoch: 04 | Epoch Time: 0m 10s\n",
            "\tTrain Loss: 0.536 | Train Acc: 73.83%\n",
            "\t Val. Loss: 0.674 |  Val. Acc: 59.63%\n",
            "Epoch: 05 | Epoch Time: 0m 10s\n",
            "\tTrain Loss: 0.640 | Train Acc: 62.84%\n",
            "\t Val. Loss: 0.514 |  Val. Acc: 77.10%\n",
            "Epoch: 06 | Epoch Time: 0m 10s\n",
            "\tTrain Loss: 0.510 | Train Acc: 76.58%\n",
            "\t Val. Loss: 0.402 |  Val. Acc: 83.58%\n",
            "Epoch: 07 | Epoch Time: 0m 10s\n",
            "\tTrain Loss: 0.307 | Train Acc: 88.21%\n",
            "\t Val. Loss: 0.335 |  Val. Acc: 86.06%\n",
            "Epoch: 08 | Epoch Time: 0m 10s\n",
            "\tTrain Loss: 0.202 | Train Acc: 92.77%\n",
            "\t Val. Loss: 0.441 |  Val. Acc: 80.91%\n",
            "Epoch: 09 | Epoch Time: 0m 10s\n",
            "\tTrain Loss: 0.153 | Train Acc: 94.99%\n",
            "\t Val. Loss: 0.363 |  Val. Acc: 86.23%\n",
            "Epoch: 10 | Epoch Time: 0m 10s\n",
            "\tTrain Loss: 0.104 | Train Acc: 96.90%\n",
            "\t Val. Loss: 0.428 |  Val. Acc: 87.22%\n",
            "Epoch: 11 | Epoch Time: 0m 10s\n",
            "\tTrain Loss: 0.064 | Train Acc: 98.41%\n",
            "\t Val. Loss: 0.463 |  Val. Acc: 87.26%\n",
            "Epoch: 12 | Epoch Time: 0m 10s\n",
            "\tTrain Loss: 0.047 | Train Acc: 98.90%\n",
            "\t Val. Loss: 0.436 |  Val. Acc: 86.23%\n",
            "Epoch: 13 | Epoch Time: 0m 10s\n",
            "\tTrain Loss: 0.035 | Train Acc: 99.22%\n",
            "\t Val. Loss: 0.508 |  Val. Acc: 86.65%\n",
            "Epoch: 14 | Epoch Time: 0m 10s\n",
            "\tTrain Loss: 0.029 | Train Acc: 99.44%\n",
            "\t Val. Loss: 0.592 |  Val. Acc: 85.66%\n",
            "Epoch: 15 | Epoch Time: 0m 10s\n",
            "\tTrain Loss: 0.027 | Train Acc: 99.37%\n",
            "\t Val. Loss: 0.610 |  Val. Acc: 86.93%\n",
            "Epoch: 16 | Epoch Time: 0m 10s\n",
            "\tTrain Loss: 0.022 | Train Acc: 99.49%\n",
            "\t Val. Loss: 0.597 |  Val. Acc: 86.39%\n",
            "Epoch: 17 | Epoch Time: 0m 10s\n",
            "\tTrain Loss: 0.019 | Train Acc: 99.60%\n",
            "\t Val. Loss: 0.718 |  Val. Acc: 86.93%\n",
            "Epoch: 18 | Epoch Time: 0m 10s\n",
            "\tTrain Loss: 0.019 | Train Acc: 99.60%\n",
            "\t Val. Loss: 0.657 |  Val. Acc: 86.55%\n",
            "Epoch: 19 | Epoch Time: 0m 10s\n",
            "\tTrain Loss: 0.016 | Train Acc: 99.68%\n",
            "\t Val. Loss: 0.736 |  Val. Acc: 86.59%\n",
            "Epoch: 20 | Epoch Time: 0m 10s\n",
            "\tTrain Loss: 0.009 | Train Acc: 99.86%\n",
            "\t Val. Loss: 0.771 |  Val. Acc: 86.39%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqSPweZLLkB1"
      },
      "source": [
        "import csv\n",
        "\n",
        "rows=zip(trainloss,trainacc,valloss,valacc)\n",
        "with open(\"lstm.csv\", \"w\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    for row in rows:\n",
        "        writer.writerow(row)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5ihsryqaR_4"
      },
      "source": [
        "# References\n",
        "# https://github.com/bentrevett/pytorch-sentiment-analysis\n",
        "# https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}